---
title: "R for Data Science chapter 3"
author: "Alibek Galiyev"
date: "September 7, 2018"
output:
    html_document:
        keep_md: true
---

# Chapter 3

```{r load_libraries}
library(nycflights13)
library(tidyverse)
```

To try _dplyr_ package we will use nyflights13::flights data, which is all flights departed from NY in 2013. 
Let's see data itself:

```{r data}
df = nycflights13::flights

head(df)
```

This data in tibble format, which is more optimized to work with tidyverse. All columns have their own 
types as int, dbl, chr, dttm. There's 7 types in tibble dataformat:

* int - integer numbers
* dbl - real numbers
* chr - character vectors or strings
* dttm - datetime
* lgl - boolean TRUE or FALSE
* fctr - categorical variables
* date - dates

## dplyr basics
dplyr package has 5 key functions:

* filter() - select given rows from dataset
* arrange() - reorder rows
* select() - pick columns by their names
* mutate() - create new columns
* summarize() - grouping data by some summary stats

## Filter Rows
*filter()* allows to subset observations based on some logic. For example, if we want to select all 
flights from January 1st:

```{r filter}
jan1 = filter(df, month == 1, day == 1)
```

R saves result to a variable. If you want to print out filtering and assign to some variable, you can wrap 
up into parentheses.

```{r filter_and_print}
(dec25 = filter(df, month == 12, day == 25))
```


## Comparisons
R has standard comparison operators like: >, <, >=, <=, ==. Since R store finite number of digits in float 
numbers, you can observe some strange behavior:

```{r comparisons}
sqrt(2) ^ 2 == 2
```

Instead of using "==", you should use _near()_ function for those kind of comparisons.

```{r near}
near(sqrt(2)^2, 2)
```


## Logical Operators
For "and" operator you can use "&" sign, for "or" use "|", and "!" for "not".

```{r logical}
filter(df, month == 11 | month == 12)
```

Instaed of using "|" in above exercise, it is more appropriate to use %in%.

```{r in}
nov_dec = filter(df, month %in% c(11, 12))
```


## Arrange Rows with arrange()
_arrange()_ works in similar way as filter, except it just reorder rows in given columns.

```{r arrange}
arrange(df, year, month, day)
```

_desc()_ function will make reverse order of values in columns:

```{r desc_arrange}
arrange(df, desc(arr_delay))
```

Important note, that missing vaslues (NAs) are always sorted at the end!


## Select Columns with select()
With _select()_ function you can select given columns by their names.

```{r select}
select(df, year, month, day)
```

Select all columns between year and day:
```{r select_year_day}
select(df, year:day)
```

Select all columns except from year and day:

```{r select_except}
select(df, -(year:day))
```

There are some helper function to use in select:

- starts_with("a") matches column names which starts with "a"
- ends_with("a") matches column names which ends with "a"
- contains("dgh") matches column names which contains "dgh"
- matches("(.)\\1") matches column names due to regular expression
- num_range("col", 1:3) matches "col1", "col2", "col3"

To rename column name you should use _rename()_ function:

```{r rename}
rename(df, tail_num = tailnum)
```

If you want to move some columns to the begining, function _everything()_ can be helpful:

```{r everything}
select(df, time_hour, air_time, everything())
```


## Add New Variables with mutate()
_mutate()_ function used to create new variables from existing ones with some transformation functions. 

```{r mutate}
df_sml = select(df, year:day, ends_with('delay'), distance, air_time)
(mutate(df_sml, gain = arr_delay - dep_delay, speed = distance / air_time * 60))
```

*mutate()* function allow you to use previously created variables as reference:

```{r mutate2}
(mutate(df_sml, gain = arr_delay - dep_delay, hours = air_time / 60, gain_per_hour = gain / hours))
```

If you want to keep only new created variable, use _transmute()_:

```{r transmute}
(transmute(df, gain = arr_delay - dep_delay, hours = air_time / 60, gain_per_hour = gain / hours))
```

## Useful Creation Functions
There are many functions that you can use to create new variables. It includes basic arithmetic operations, 
log and exp functions, offsets like _lag()_ and _lead()_, cumulative and rolling aggregates like _cumsum()_, 
_cumprod()_, _cummin()_, _cummax()_, _cummean()_, logical opeartions like ">", "<", ">=", "<=", rankings 
like *min_rank()*, *row_number()*, *dense_rank()*, *percent_rank()*, *cume_dist()*, *ntitle()*. 


## Grouped Summaries with summarize()
*summarize()* function collapse a data frame to a single row. It's useful with *group_by()* function. For 
example if you want to obtain average delay per day:

```{r avg_delay}
(group_by(df, year, month, day) %>%
     summarize(delay = mean(dep_delay, na.rm = T)))
```


## Combining Multiple Operations with the Pipe
If you want to get relationship between distance and average delay, you can get data with *group_by()*, 
*summarize()* and *filter()*:

```{r dist_vs_delay}
delay = df %>%
    group_by(dest) %>%
    summarize(count = n(),
              dist = mean(distance, na.rm = T),
              delay = mean(arr_delay, na.rm = T)) %>%
    filter(count > 20, dest != "HNL")

ggplot(data = delay, mapping = aes(x = dist, y = delay)) + 
    geom_point(aes(size = count), alpha = 1/3) + 
    geom_smooth(se = F)
```


## Missing Values
If you don't use na.rm argument, aggregate functions in summarize yield _na_ values. 

```{r na_values}
(df %>%
     group_by(year, month, day) %>%
     summarize(mean = mean(dep_delay)))
```

If there's any _na_ values in column, aggregate functions always return _na_ values for entire result. 
Fortunately, all aggregate functions have _na.rm_ argument, which removes missing values prior to calculation. 

```{r na_rm}
(df %>%
     group_by(year, month, day) %>%
     summarize(mean = mean(dep_delay, na.rm = T)))
```


## Count
It is always good idea to include _count_ to aggregated data with _n()_, or count of non-na values with 
_sum(!is.na(x))_. It helps you to avoid working with small number of observations in aggreagted data. 
For example let's plot highest average delays identified by tailnum:

```{r delays_mean}
delays = df %>%
    filter(!is.na(dep_delay), !is.na(arr_delay)) %>%
    group_by(tailnum) %>%
    summarize(delay = mean(arr_delay))

ggplot(data = delays, mapping = aes(x = delay)) + 
    geom_freqpoly(binwidth = 10)
```

From plot above you can see that some planes have 5 hours average delays. But if you plot scatterplot 
of average delay and number of observations, you can understand that plot above is not reliable:

```{r delays_cnt}
delays = df %>%
    filter(!is.na(arr_delay), !is.na(dep_delay)) %>%
    group_by(tailnum) %>%
    summarize(delay = mean(arr_delay, na.rm = T)
              ,n = n())

ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1/10)
```

You should notice that with smaller number of observations, you have bigger variations of average delays. 
So, it is a good idea to filter out small number of observations from data frame:

```{r filter_out_small_observations}
delays %>%
    filter(n > 25) %>%
    ggplot(mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1 / 10)
```


## Useful Summary Functions
Sometimes _median_ value more useful than _mean_. Also, you can use some logical subsetting in _summarize_ 
function.

```{r logical_subset}
(df %>%
    filter(!is.na(arr_delay)) %>%
    group_by(year, month, day) %>%
    summarize(avg_delay1 = mean(arr_delay, na.rm = T)
              ,avg_delay2 = mean(arr_delay[arr_delay > 0], na.rm = T)
              ,median_delay = median(arr_delay, na.rm = T)))
```

Measures of spread like standard deviation (sd), interquartile range (IQR) and median absolute deviation 
(mad) are very useful functions to understand data.

```{r spread_measures}
(df %>%
    group_by(dest) %>%
    summarize(distance_sd = sd(distance, na.rm = T)
              ,distance_IQR = IQR(distance, na.rm = T)
              ,distance_mad = mad(distance, na.rm = T)))
```

Measures of rank help to find particular quantile value, or min, max values:

```{r rank_measures}
(df %>%
     group_by(year, month, day) %>%
     summarize(first = min(dep_time, na.rm = T)
               ,last = max(dep_time, na.rm = T)
               ,q25 = quantile(dep_time, 0.25, na.rm = T)
               ,q75 = quantile(dep_time, 0.75, na.rm = T)))
```

Counts calculated not only with _n()_, but also with _sum(!is.na(x))_ for non-missing values, *n_distinct()* 
for distinct amount of values:

```{r counts}
(df %>%
    group_by(dest) %>%
    summarize(cnt = n()
              ,cnt_distinct = n_distinct(carrier)) %>%
    arrange(desc(cnt_distinct)))
```




























